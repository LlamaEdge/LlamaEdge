name: Build

on:
  push:
    branches:
      - dev
      - main
      - release-*
      - feat-*
      - ci-*
      - refactor-*
      - fix-*
      - test-*
    paths:
      - '.github/workflows/**'
      - '**/Cargo.toml'
      - '**/*.rs'
      - '**/*.sh'
      - '**/.cargo/config.toml'
  pull_request:
    branches:
      - dev
      - main
    types: [opened, synchronize, reopened]
    paths:
      - '.github/workflows/**'
      - '**/Cargo.toml'
      - '**/*.rs'
      - '**/*.sh'

jobs:
  build-wasm:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-22.04, ubuntu-20.04, macos-13, macos-14]
    steps:
      - name: Clone project
        id: checkout
        uses: actions/checkout@v3

      - name: Install Rust-nightly
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: nightly
          target: wasm32-wasip1
          components: rustfmt, clippy

      - name: Install Rust-stable
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          target: wasm32-wasip1

      - name: Download wasi-sdk for x86_64-macos
        if: matrix.os == 'macos-13'
        run: |
          curl -LO https://github.com/WebAssembly/wasi-sdk/releases/download/wasi-sdk-24/wasi-sdk-24.0-x86_64-macos.tar.gz
          tar -xzvf wasi-sdk-24.0-x86_64-macos.tar.gz
          mv wasi-sdk-24.0-x86_64-macos wasi-sdk-24.0

      - name: Download wasi-sdk for arm64-macos
        if: matrix.os == 'macos-14'
        run: |
          curl -LO https://github.com/WebAssembly/wasi-sdk/releases/download/wasi-sdk-24/wasi-sdk-24.0-arm64-macos.tar.gz
          tar -xzvf wasi-sdk-24.0-arm64-macos.tar.gz
          mv wasi-sdk-24.0-arm64-macos wasi-sdk-24.0

      - name: Run clippy
        if: startsWith(matrix.os, 'ubuntu')
        env:
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo +nightly clippy --target wasm32-wasip1 -- -D warnings

      - name: Run fmt
        if: startsWith(matrix.os, 'ubuntu')
        env:
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo +nightly fmt --all -- --check

      - name: Run tests on linux
        if: startsWith(matrix.os, 'ubuntu')
        env:
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo test -p endpoints --target x86_64-unknown-linux-gnu

      - name: Run tests on macos-14
        if: matrix.os == 'macos-14'
        env:
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo test -p endpoints --target aarch64-apple-darwin

      - name: Build llama-simple
        env:
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo build -p llama-simple --release

      - name: Build llama-chat on linux
        if: startsWith(matrix.os, 'ubuntu')
        env:
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo build -p llama-chat --release

      - name: Build llama-chat on macos
        if: startsWith(matrix.os, 'macos')
        env:
          WASI_SDK_PATH: /Users/runner/work/LlamaEdge/LlamaEdge/wasi-sdk-24.0
          CC: "/Users/runner/work/LlamaEdge/LlamaEdge/wasi-sdk-24.0/bin/clang --sysroot=/Users/runner/work/LlamaEdge/LlamaEdge/wasi-sdk-24.0/share/wasi-sysroot"
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo build -p llama-chat --release

      - name: Build llama-api-server on linux
        if: startsWith(matrix.os, 'ubuntu')
        env:
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo build -p llama-api-server --release

      - name: Build api-server on macos
        if: startsWith(matrix.os, 'macos')
        env:
          WASI_SDK_PATH: /Users/runner/work/LlamaEdge/LlamaEdge/wasi-sdk-24.0
          CC: "/Users/runner/work/LlamaEdge/LlamaEdge/wasi-sdk-24.0/bin/clang --sysroot=/Users/runner/work/LlamaEdge/LlamaEdge/wasi-sdk-24.0/share/wasi-sysroot"
          RUSTFLAGS: "--cfg wasmedge --cfg tokio_unstable"
        run: |
          cargo build -p llama-api-server --release
